{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-textsum.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0AAVDL1wTigYIJTcM4s14",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hailusong/nlp-qa/blob/master/nlp_textsum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-mZgVZMlbDh",
        "colab_type": "text"
      },
      "source": [
        "#### **Text Summarization**\n",
        "Refs:\n",
        "- https://huggingface.co/models\n",
        "- https://huggingface.co/models?search=bertabs\n",
        "- [BertForMaskedLM](https://github.com/huggingface/transformers/blob/13aa174112f0c2ee794c44188ecf13b241694db0/src/transformers/modeling_bert.py#L876) used as architecture in BertAbs model, which can do\n",
        "  * **masked language modeling** loss, for language modeling, or\n",
        "  * left-to-right language modeling loss (**next word prediction**)\n",
        "\n",
        "Hyper-params:\n",
        "TBA\n",
        "\n",
        "Issues:\n",
        "1. Max sentence length: 64 (truncated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK4Aexd2YLi9",
        "colab_type": "text"
      },
      "source": [
        "## Environment Setup\n",
        "To get the source code of Huggingface transformer release, do this (assuming the release version is 2.11.0)\n",
        "```\n",
        "git fetch -a --tags\n",
        "git checkout tags/v2.11.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYM3yVozc9uj",
        "colab_type": "text"
      },
      "source": [
        "Make sure we have access to file command in Linux"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "799C3kzOcqb4",
        "colab_type": "code",
        "outputId": "877460ca-5e45-4f7f-a2d6-a3c4a65233f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "!uname -a\n",
        "!pip install wget\n",
        "!apt-get install file"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux 49ba081d07d6 4.19.104+ #1 SMP Wed Feb 19 05:26:34 PST 2020 x86_64 x86_64 x86_64 GNU/Linux\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=85bdb9dccbca33b9797cdc19b61272b80f3a11cfa2e42bbd00a89348f11719f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libmagic-mgc libmagic1\n",
            "The following NEW packages will be installed:\n",
            "  file libmagic-mgc libmagic1\n",
            "0 upgraded, 3 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 275 kB of archives.\n",
            "After this operation, 5,297 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Fetched 275 kB in 1s (443 kB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpUI_vQISUii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "151a8fc6-8bcc-4730-8c65-52e7f3b93556"
      },
      "source": [
        "try:\n",
        "    import transformers\n",
        "except ImportError as e:\n",
        "    # install huggingface\n",
        "    !pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 15.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 17.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 23.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=7f07fbea916716cf847951323fc37f280e07c56b7b249ad49a5e6b44087b7e87\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Guw8jy8IRy3Q",
        "colab_type": "code",
        "outputId": "110f6471-1526-4934-93ec-4847b3a9b43c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "print(torch.__version__)\n",
        "print(transformers.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n",
            "2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tcrZk3mrW8F",
        "colab_type": "text"
      },
      "source": [
        "## Configuratiuon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QPgyarrrY_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EXAMPLE_MODE=True\n",
        "INLINE_MODE=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzR-3Gj3fgVZ",
        "colab_type": "code",
        "outputId": "a199a3c6-b370-4e5b-948d-d8c241f62353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "if EXAMPLE_MODE:\n",
        "  # ! [ ! -d \"./transformers\" ] && git clone --depth 1 https://github.com/huggingface/transformers\n",
        "  # ! [ -d \"./transformers\" ] && \\\n",
        "  #   cd transformers && \\\n",
        "  #   git fetch -a --tags && \\\n",
        "  #   git checkout tags/v2.11.0 && \\\n",
        "  #   pip install . && \\\n",
        "  !rm -rf ./nlp-qa/\n",
        "  ![ ! -d \"./nlp-qa\" ] && git clone --depth 1 https://github.com/hailusong/nlp-qa.git\n",
        "  !pip install nltk py-rouge"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp-qa'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 45 (delta 2), reused 29 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (45/45), done.\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Collecting py-rouge\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/1d/0bdbaf559fb7afe32308ebc84a2028600988212d7eb7fb9f69c4e829e4a0/py_rouge-1.1-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Installing collected packages: py-rouge\n",
            "Successfully installed py-rouge-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoWqnJwhO7Ls",
        "colab_type": "text"
      },
      "source": [
        "### GPU Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwRRhY4zO8fy",
        "colab_type": "code",
        "outputId": "e251c9ea-82d8-490b-e72c-f0612b0ce2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ1AUfsqlwa0",
        "colab_type": "text"
      },
      "source": [
        "## Download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WSQ93jDoh14",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained BERTABS fine-tuned on CNN/DM corpus \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exGaF-bRoRCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if INLINE_MODE:\n",
        "  # from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "  # from transformers import AlbertConfig, AlbertForSequenceClassification\n",
        "  # import torch\n",
        "  from modeling_bertabs import BertAbs, build_predictor\n",
        "  from transformers import BertTokenizer\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "  model = BertAbs.from_pretrained(\"bertabs-finetuned-cnndm\")\n",
        "  model.to(args.device)\n",
        "  model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ffzmDA9tYXb",
        "colab_type": "text"
      },
      "source": [
        "### Text to be summarized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIZPkjCsteSI",
        "colab_type": "code",
        "outputId": "324576af-e1bb-4169-b490-c32a19c81236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "if EXAMPLE_MODE:\n",
        "  %env DATA_PATH=/content/nlp-qa/stories\n",
        "  %env SUMMARIES_PATH=/content/textsum-out\n",
        "\n",
        "  !mkdir -p $SUMMARIES_PATH\n",
        "  !ls -al $SUMMARIES_PATH\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: DATA_PATH=/content/nlp-qa/stories\n",
            "env: SUMMARIES_PATH=/content/textsum-out\n",
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Jun 10 13:25 .\n",
            "drwxr-xr-x 1 root root 4096 Jun 10 13:25 ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxUPF8mHEuEq",
        "colab_type": "text"
      },
      "source": [
        "## Inference\n",
        "Source: https://pytorch.org/hub/huggingface_pytorch-transformers/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GMmocddvlOw",
        "colab_type": "text"
      },
      "source": [
        "### BertAbs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v34KA-DEywd1",
        "colab_type": "code",
        "outputId": "6b5412d7-8db0-47de-bd5d-d44cd3c15697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if EXAMPLE_MODE:\n",
        "  # !pwd\n",
        "  # !ls -al transformers/examples/summarization/bertabs\n",
        "  # !cd transformers/examples/summarization/bertabs && python run_summarization.py \\\n",
        "  #   --documents_dir $DATA_PATH \\\n",
        "  #   --summaries_output_dir $SUMMARIES_PATH \\\n",
        "  #   --no_cuda false \\\n",
        "  #   --batch_size 4 \\\n",
        "  #   --min_length 50 \\\n",
        "  #   --max_length 200 \\\n",
        "  #   --beam_size 5 \\\n",
        "  #   --alpha 0.95 \\\n",
        "  #   --block_trigram true\n",
        "  # !ls -al nlp-qa/textsum/bertabs\n",
        "  !cd nlp-qa/textsum/bertabs && python run_summarization.py \\\n",
        "    --documents_dir $DATA_PATH \\\n",
        "    --summaries_output_dir $SUMMARIES_PATH \\\n",
        "    --no_cuda false \\\n",
        "    --batch_size 4 \\\n",
        "    --min_length 20 \\\n",
        "    --max_length 50 \\\n",
        "    --beam_size 5 \\\n",
        "    --alpha 0.95 \\\n",
        "    --block_trigram true"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-10 13:25:29.345043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "INFO:filelock:Lock 140646512241520 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpo33_kwov\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 4.18MB/s]\n",
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:filelock:Lock 140646512241520 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:filelock:Lock 140646511767736 acquired on /root/.cache/torch/transformers/9d982039993bba60a064b70f3d5733f091aefc83eef2f1cd222242ca2f4fd0d9.d524a81afda9167a3e76519785c0610c76f5647e45b9c17a8849f7fe0088cf5f.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp5vr7t7ei\n",
            "Downloading: 100% 666/666 [00:00<00:00, 500kB/s]\n",
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization/config.json in cache at /root/.cache/torch/transformers/9d982039993bba60a064b70f3d5733f091aefc83eef2f1cd222242ca2f4fd0d9.d524a81afda9167a3e76519785c0610c76f5647e45b9c17a8849f7fe0088cf5f\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/9d982039993bba60a064b70f3d5733f091aefc83eef2f1cd222242ca2f4fd0d9.d524a81afda9167a3e76519785c0610c76f5647e45b9c17a8849f7fe0088cf5f\n",
            "INFO:filelock:Lock 140646511767736 released on /root/.cache/torch/transformers/9d982039993bba60a064b70f3d5733f091aefc83eef2f1cd222242ca2f4fd0d9.d524a81afda9167a3e76519785c0610c76f5647e45b9c17a8849f7fe0088cf5f.lock\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization/config.json from cache at /root/.cache/torch/transformers/9d982039993bba60a064b70f3d5733f091aefc83eef2f1cd222242ca2f4fd0d9.d524a81afda9167a3e76519785c0610c76f5647e45b9c17a8849f7fe0088cf5f\n",
            "INFO:transformers.configuration_utils:Model config BertAbsConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"dec_dropout\": 0.2,\n",
            "  \"dec_ff_size\": 2048,\n",
            "  \"dec_heads\": 8,\n",
            "  \"dec_hidden_size\": 768,\n",
            "  \"dec_layers\": 6,\n",
            "  \"enc_dropout\": 0.2,\n",
            "  \"enc_ff_size\": 512,\n",
            "  \"enc_heads\": 8,\n",
            "  \"enc_hidden_size\": 512,\n",
            "  \"enc_layers\": 6,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_pos\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bertabs\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:filelock:Lock 140646512242528 acquired on /root/.cache/torch/transformers/a8eb33263409540b0986df2844c815c973e453432ff22805e5ed0c1ec585d98c.f7b70c5121ce72aad107e20f528d8fd88aa9da525c556aeadeab0c0421696223.lock\n",
            "INFO:transformers.file_utils:https://cdn.huggingface.co/remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpbk2z8jww\n",
            "Downloading: 100% 886M/886M [08:02<00:00, 1.84MB/s]\n",
            "INFO:transformers.file_utils:storing https://cdn.huggingface.co/remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization/pytorch_model.bin in cache at /root/.cache/torch/transformers/a8eb33263409540b0986df2844c815c973e453432ff22805e5ed0c1ec585d98c.f7b70c5121ce72aad107e20f528d8fd88aa9da525c556aeadeab0c0421696223\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/a8eb33263409540b0986df2844c815c973e453432ff22805e5ed0c1ec585d98c.f7b70c5121ce72aad107e20f528d8fd88aa9da525c556aeadeab0c0421696223\n",
            "INFO:filelock:Lock 140646512242528 released on /root/.cache/torch/transformers/a8eb33263409540b0986df2844c815c973e453432ff22805e5ed0c1ec585d98c.f7b70c5121ce72aad107e20f528d8fd88aa9da525c556aeadeab0c0421696223.lock\n",
            "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization/pytorch_model.bin from cache at /root/.cache/torch/transformers/a8eb33263409540b0986df2844c815c973e453432ff22805e5ed0c1ec585d98c.f7b70c5121ce72aad107e20f528d8fd88aa9da525c556aeadeab0c0421696223\n",
            "INFO:filelock:Lock 140646512240232 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp8zuipvzf\n",
            "Downloading: 100% 433/433 [00:00<00:00, 287kB/s]\n",
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "INFO:filelock:Lock 140646512240232 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "INFO:transformers.configuration_utils:Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:__main__:***** Running evaluation *****\n",
            "INFO:__main__:  Number examples = 8\n",
            "INFO:__main__:  Batch size = 4\n",
            "INFO:__main__:\n",
            "INFO:__main__:***** Beam Search parameters *****\n",
            "INFO:__main__:  Beam size = 5\n",
            "INFO:__main__:  Minimum length = 20\n",
            "INFO:__main__:  Maximum length = 50\n",
            "INFO:__main__:  Alpha (length penalty) = 0.95\n",
            "INFO:__main__:  Trigrams will be blocked\n",
            "  0% 0/2 [00:00<?, ?it/s]/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
            "100% 2/2 [00:51<00:00, 25.55s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9mTlxoRvpJU",
        "colab_type": "text"
      },
      "source": [
        "### BART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC-0O7nIJ-SJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if EXAMPLE_MODE:\n",
        "  !cd nlp-qa/textsum/bertabs && python evaluate_cnn.py $DATA_PATH $SUMMARIES_PATH/bart_cnn_test_summaries.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcBXYJ7bv-BQ",
        "colab_type": "text"
      },
      "source": [
        "### Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by-nlDGNioOw",
        "colab_type": "code",
        "outputId": "9740e567-1cf2-4082-d496-67b7447d3002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!ls -al $SUMMARIES_PATH\n",
        "!grep \"\" $SUMMARIES_PATH/*"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 40\n",
            "drwxr-xr-x 2 root root 4096 Jun 10 13:34 .\n",
            "drwxr-xr-x 1 root root 4096 Jun 10 13:25 ..\n",
            "-rw-r--r-- 1 root root  206 Jun 10 13:34 e117408ad19cc69e15b1e21b9ae54f10c07223ce_summary.story\n",
            "-rw-r--r-- 1 root root  252 Jun 10 13:34 e3dd06d326c8d53722bdc5c8428e29c68a60d0d5_summary.story\n",
            "-rw-r--r-- 1 root root  228 Jun 10 13:34 e9093ca0a82f2aba28cd2762942c04177cfbb000_summary.story\n",
            "-rw-r--r-- 1 root root  198 Jun 10 13:34 ea06fd0b25cb9793397a51de73fd83f91b4323fa_summary.story\n",
            "-rw-r--r-- 1 root root  243 Jun 10 13:34 eb68bc51ed4fc727a1af058192a3fef0916c91e7_summary.story\n",
            "-rw-r--r-- 1 root root  267 Jun 10 13:34 ee0ba7928d8987f2cb21c9a2012a76730f77de45_summary.story\n",
            "-rw-r--r-- 1 root root  218 Jun 10 13:34 ee8871b15c50d0db17b0179a6d2beab35065f1e9_summary.story\n",
            "-rw-r--r-- 1 root root  255 Jun 10 13:34 mine1_summary.story\n",
            "/content/textsum-out/e117408ad19cc69e15b1e21b9ae54f10c07223ce_summary.story:the partnership is an organization with partners throughout the uk. it employs approximately 67 , 100 people. each partner receives the same scale of bonus , based on a fixed percentage of their annual wage\n",
            "/content/textsum-out/e3dd06d326c8d53722bdc5c8428e29c68a60d0d5_summary.story:six south carolina students were able to get out of the house in time. six others were treated and released from hospital , but auman 's daughter is in stable condition. the fire department arrived on the scene , about five minutes after being notified\n",
            "/content/textsum-out/e9093ca0a82f2aba28cd2762942c04177cfbb000_summary.story:cpl. trent d. thomas was found guilty of kidnapping and conspiracy to commit several offenses. thomas was among seven marines and a navy medic who were charged in connection with the death of hashim ibrahim awad. the 25-year-old\n",
            "/content/textsum-out/ea06fd0b25cb9793397a51de73fd83f91b4323fa_summary.story:barcelona beat atletico madrid 3- 0-0 at the nou camp in el clasico. lionel messi scored twice in the first half for the spanish giants. the result leaves the catalan giants top of the spanish table\n",
            "/content/textsum-out/eb68bc51ed4fc727a1af058192a3fef0916c91e7_summary.story:honey bees are responsible for pollinating $ 15 billion worth of apples each year. more than 90 fruits and vegetables worldwide depend on them for pollination. the disorder is marked by hives left with a queen , a few newly hatched adults. but\n",
            "/content/textsum-out/ee0ba7928d8987f2cb21c9a2012a76730f77de45_summary.story:all of the unidentified victims - thai embassy officials - were foreign nationals. thai health minister mongkol na songkhla said that of the 41 survivors who remain hospitalized , 38 are in stable condition and three are still in critical condition. the investigation\n",
            "/content/textsum-out/ee8871b15c50d0db17b0179a6d2beab35065f1e9_summary.story:most often , they face drug charges or charges of assaulting an officer. inmates become more paranoid , delusional , and less likely to follow directions. judge steven leifman says most people in miami are mentally ill\n",
            "/content/textsum-out/mine1_summary.story:we will be limiting the number of patients at the clinic at all times. upon booking an appointment , we will pre - screen every client before they are permitted to visit. if you have traveled recently , feel under the weather or are taking care of someone\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}