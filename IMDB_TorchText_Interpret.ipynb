{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "IMDB_TorchText_Interpret.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hailusong/nlp-qa/blob/master/IMDB_TorchText_Interpret.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "9BRoF9DxMJvl",
        "colab_type": "text"
      },
      "source": [
        "# Interpreting text models:  IMDB sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJkvrGWnMJvn",
        "colab_type": "text"
      },
      "source": [
        "This notebook loads pretrained CNN model for sentiment analysis on IMDB dataset. It makes predictions on test samples and interprets those predictions using integrated gradients method.\n",
        "\n",
        "The model was trained using an open source sentiment analysis tutorials described in: https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
        "\n",
        "**Note:** Before running this tutorial, please install the spacy package, and its NLP modules for English language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GTWutJGawyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "f0cde409-ca2a-450d-b163-475a73ec9f6f"
      },
      "source": [
        "!pip install spacy\n",
        "!pip install captum\n",
        "\n",
        "# nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.3.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from captum) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from captum) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from captum) (1.5.1+cu101)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->captum) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->captum) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74-UfkhTMJvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "import torchtext.data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization\n",
        "\n",
        "nlp = spacy.load('en')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4kPEV7cMJvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA3ByRG8MJv1",
        "colab_type": "text"
      },
      "source": [
        "The dataset used for training this model can be found in: https://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n",
        "Redefining the model in order to be able to load it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtQteL3TcAbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "![ ! -d \"aclImdb\" ] && wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "![ ! -d \"aclImdb\" ] && gunzip aclImdb_v1.tar.gz\n",
        "![ ! -d \"aclImdb\" ] && tar -xf aclImdb_v1.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrx5chvqMJv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "                \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv2d(in_channels = 1, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = (fs, embedding_dim)) \n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        #text = text.permute(1, 0)\n",
        "                \n",
        "        #text = [batch size, sent len]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "            \n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "                \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        results = self.fc(cat)\n",
        "        print(f'model forward: {results.shape}')\n",
        "        return results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4mtF9O6MJv7",
        "colab_type": "text"
      },
      "source": [
        "Loads pretrained model and sets the model to eval mode.\n",
        "\n",
        "The model can be downloaded here: https://github.com/pytorch/captum/blob/master/tutorials/models/imdb-model-cnn.pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M-ka6Soa7OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "![ ! -f imdb-model-cnn.pt ] && wget https://github.com/pytorch/captum/raw/master/tutorials/models/imdb-model-cnn.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1P99tBjMJv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "1869d082-fbda-4e62-8839-a2c8d5f32b70"
      },
      "source": [
        "model = torch.load('imdb-model-cnn.pt')\n",
        "model.eval()\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHl55RPiMJwB",
        "colab_type": "text"
      },
      "source": [
        "Forward function that supports sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iQsXWU8MJwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_with_sigmoid(input):\n",
        "    mode_result = model(input)\n",
        "    result = torch.sigmoid(mode_result)\n",
        "    print(f'model: {mode_result}, sigmoid: {result}')\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlo2pEM7MJwP",
        "colab_type": "text"
      },
      "source": [
        "Load a small subset of test data using torchtext from IMDB dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCPSxRHIMJwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = torchtext.data.Field(lower=True, tokenize='spacy')\n",
        "Label = torchtext.data.LabelField(dtype = torch.float)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqffd3joMJwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = torchtext.datasets.IMDB.splits(text_field=TEXT,\n",
        "                                      label_field=Label,\n",
        "                                      train='train',\n",
        "                                      test='test',\n",
        "                                      path='aclImdb')\n",
        "test, _ = test.split(split_ratio = 0.04)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw4Sa01nrTnr",
        "colab_type": "text"
      },
      "source": [
        "Download glove embedding glove.6B.50d.txt. However, it seems glove.6B.50d.txt is only availabke from Kaggle and the Kaggle downloading requires login first. The workaround is to download full 6B package (822M) from Stanford and then use the 50d version only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bOuEQZ2rWV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0b2adb2-59ee-496f-e049-6bb00bd0cc75"
      },
      "source": [
        "![ ! -f glove.6B.50d.txt ] && wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "![ ! -f glove.6B.50d.txt ] && unzip glove.6B.zip\n",
        "!ls -al glove.6B.50d.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-rw-r-- 1 root root 171350079 Aug  4  2014 glove.6B.50d.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-I2OdBPMJwZ",
        "colab_type": "text"
      },
      "source": [
        "Loading and setting up vocabulary for word embeddings using torchtext."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE9HXiFIMJwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import vocab\n",
        "\n",
        "#loaded_vectors = vocab.GloVe(name='6B', dim=50)\n",
        "\n",
        "# If you prefer to use pre-downloaded glove vectors, you can load them with the following two command line\n",
        "loaded_vectors = torchtext.vocab.Vectors('glove.6B.50d.txt')\n",
        "TEXT.build_vocab(train, vectors=loaded_vectors, max_size=len(loaded_vectors.stoi))\n",
        "    \n",
        "TEXT.vocab.set_vectors(stoi=loaded_vectors.stoi, vectors=loaded_vectors.vectors, dim=loaded_vectors.dim)\n",
        "Label.build_vocab(train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFLciIBTMJwf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3bb2c24-4c45-49c7-ab1d-bf8de776ee51"
      },
      "source": [
        "print('Vocabulary Size: ', len(TEXT.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size:  101520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8RlKZHaMJwk",
        "colab_type": "text"
      },
      "source": [
        "In order to apply Integrated Gradients and many other interpretability algorithms on sentences, we need to create a reference (aka baseline) for the sentences and its constituent parts, tokens.\n",
        "\n",
        "Captum provides a helper class called `TokenReferenceBase` which allows us to generate a reference for each input text using the number of tokens in the text and a reference token index.\n",
        "\n",
        "To use `TokenReferenceBase` we need to provide a `reference_token_idx`. Since padding is one of the most commonly used references for tokens, padding index is passed as reference token index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KfpXApLMJwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD_IND = TEXT.vocab.stoi['pad']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEK8LWfoMJwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQhDqeOfMJwy",
        "colab_type": "text"
      },
      "source": [
        "Let's create an instance of `LayerIntegratedGradients` using forward function of our model and the embedding layer.\n",
        "This instance of layer integrated gradients will be used to interpret movie rating review.\n",
        "\n",
        "Layer Integrated Gradients will allow us to assign an attribution score to each word/token embedding tensor in the movie review text. We will ultimately sum the attribution scores across all embedding dimensions for each word/token in order to attain a word/token level attribution score.\n",
        "\n",
        "Note that we can also use `IntegratedGradients` class instead, however in that case we need to precompute the embeddings and wrap Embedding layer with `InterpretableEmbeddingBase` module. This is necessary because we cannot perform input scaling and subtraction on the level of word/token indices and need access to the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mIXSkZ4MJwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lig = LayerIntegratedGradients(model, model.embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjBIc2e4MJw3",
        "colab_type": "text"
      },
      "source": [
        "In the cell below, we define a generic function that generates attributions for each movie rating and stores them in a list using `VisualizationDataRecord` class. This will ultimately be used for visualization purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fjF0K7LMJw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accumalate couple samples in this array for visualization purposes\n",
        "vis_data_records_ig = []\n",
        "\n",
        "def interpret_sentence(model, sentence, min_len = 7, label = 0):\n",
        "    text = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    if len(text) < min_len:\n",
        "        text += ['pad'] * (min_len - len(text))\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in text]\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    input_indices = torch.tensor(indexed, device=device)\n",
        "    input_indices = input_indices.unsqueeze(0)\n",
        "    \n",
        "    # input_indices dim: [sequence_length]\n",
        "    seq_length = min_len\n",
        "\n",
        "    # predict\n",
        "    pred = forward_with_sigmoid(input_indices).item()\n",
        "    pred_ind = round(pred)\n",
        "\n",
        "    # generate reference indices for each sample\n",
        "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
        "\n",
        "    # compute attributions and approximation delta using layer integrated gradients\n",
        "    attributions_ig, delta = lig.attribute(input_indices, reference_indices, \\\n",
        "                                           n_steps=500, return_convergence_delta=True)\n",
        "\n",
        "    print('pred: ', Label.vocab.itos[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
        "\n",
        "    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n",
        "    \n",
        "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
        "    attributions = attributions.sum(dim=2).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    attributions = attributions.cpu().detach().numpy()\n",
        "\n",
        "    # storing couple samples in an array for visualization purposes\n",
        "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
        "                            attributions,\n",
        "                            pred,\n",
        "                            Label.vocab.itos[pred_ind],\n",
        "                            Label.vocab.itos[label],\n",
        "                            Label.vocab.itos[1],\n",
        "                            attributions.sum(),       \n",
        "                            text,\n",
        "                            delta))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwz6-bcDMJw_",
        "colab_type": "text"
      },
      "source": [
        "Below cells call `interpret_sentence` to interpret a couple handcrafted review phrases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqbziOhqMJxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "47298e76-4a9e-40b8-f465-4d6820bbc502"
      },
      "source": [
        "interpret_sentence(model, 'It was a fantastic performance !', label=1)\n",
        "interpret_sentence(model, 'Best film ever', label=1)\n",
        "interpret_sentence(model, 'Such a great show!', label=1)\n",
        "interpret_sentence(model, 'It was a horrible movie', label=0)\n",
        "interpret_sentence(model, 'I\\'ve never watched something as bad', label=0)\n",
        "interpret_sentence(model, 'It is a disgusting movie!', label=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model forward: torch.Size([1, 1])\n",
            "model: tensor([[4.5194]], device='cuda:0', grad_fn=<AddmmBackward>), sigmoid: tensor([[0.9892]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([500, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "pred:  pos ( 0.99 ) , delta:  tensor([2.2484e-05], device='cuda:0', dtype=torch.float64)\n",
            "model forward: torch.Size([1, 1])\n",
            "model: tensor([[6.3903]], device='cuda:0', grad_fn=<AddmmBackward>), sigmoid: tensor([[0.9983]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([500, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "pred:  pos ( 1.00 ) , delta:  tensor([6.6844e-05], device='cuda:0', dtype=torch.float64)\n",
            "model forward: torch.Size([1, 1])\n",
            "model: tensor([[5.7295]], device='cuda:0', grad_fn=<AddmmBackward>), sigmoid: tensor([[0.9968]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([500, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "pred:  pos ( 1.00 ) , delta:  tensor([0.0003], device='cuda:0', dtype=torch.float64)\n",
            "model forward: torch.Size([1, 1])\n",
            "model: tensor([[0.7934]], device='cuda:0', grad_fn=<AddmmBackward>), sigmoid: tensor([[0.6886]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([500, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "pred:  pos ( 0.69 ) , delta:  tensor([0.0003], device='cuda:0', dtype=torch.float64)\n",
            "model forward: torch.Size([1, 1])\n",
            "model: tensor([[-1.2861]], device='cuda:0', grad_fn=<AddmmBackward>), sigmoid: tensor([[0.2165]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([500, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "pred:  neg ( 0.22 ) , delta:  tensor([0.0011], device='cuda:0', dtype=torch.float64)\n",
            "model forward: torch.Size([1, 1])\n",
            "model: tensor([[1.4172]], device='cuda:0', grad_fn=<AddmmBackward>), sigmoid: tensor([[0.8049]], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([500, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "model forward: torch.Size([1, 1])\n",
            "pred:  pos ( 0.80 ) , delta:  tensor([0.0008], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bolva1eVMJxF",
        "colab_type": "text"
      },
      "source": [
        "Below is an example of how we can visualize attributions for the text tokens. Feel free to visualize it differently if you choose to have a different visualization method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71uYkxCHMJxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "0601f237-74b1-49f3-9d22-0ad27a826593"
      },
      "source": [
        "print('Visualize attributions based on Integrated Gradients')\n",
        "visualization.visualize_text(vis_data_records_ig)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Visualize attributions based on Integrated Gradients\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.61</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-1.10</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Best                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(0, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.59</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Such                    </font></mark><mark style=\"background-color: hsl(0, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 69%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> show                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.69)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-1.82</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horrible                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.22)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-2.45</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 've                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> never                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watched                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.80)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-2.02</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disgusting                    </font></mark><mark style=\"background-color: hsl(0, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLizf49VMJxL",
        "colab_type": "text"
      },
      "source": [
        "Above cell generates an output similar to this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXbxgolOMJxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e208598-721b-42fd-d0a4-1757dbe9c515"
      },
      "source": [
        "# from IPython.display import Image\n",
        "# Image(filename='img/sentiment_analysis.png')\n",
        "round(0.499), round(0.599)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LDe1sHp2_F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}